{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565bfcdb-ed8c-4260-b8c6-1efa81cfc369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset using kaggle api\n",
    "import kaggle\n",
    "!kaggle datasets download ankitbansal06/retail-orders -f orders.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f26140-96d2-4000-8880-7065e3cc1c2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract file from a zipfile\n",
    "\n",
    "import zipfile\n",
    "zip_file = zipfile.ZipFile('orders.csv.zip')\n",
    "zip_file.extractall()  #extracting zipfile to dir\n",
    "zip_file.close()   #close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6ab16a9-d4e2-4ad7-b068-e1611aa1b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from the file and handle null values\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('orders.csv')\n",
    "#df.head(20)\n",
    "#df['Ship Mode'].unique()\n",
    "\n",
    "# in this case we see that we have 'Not Available' and 'Unknown' values in ship mode column and we want to make them null/nan values in the file\n",
    "# so we are going to add na_values when reading a file in order to handle null values in the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1071619a-fc73-40cc-8d65-4b630f52c593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Second Class', 'Standard Class', nan, 'First Class', 'Same Day'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handling null values\n",
    "\n",
    "df = pd.read_csv('orders.csv', na_values= ['Not Available','unknown'])\n",
    "df.head(20)\n",
    "df['Ship Mode'].unique()  #now we have all the null values as nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f67fd75-7e26-484f-8323-599387ddbdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename column names.. make them lower case and replace space with underscore\n",
    "\n",
    "#df.rename(columns={'Order Id': 'order_id', 'City': 'city'})  #but this is not a good practice as there are 15 columns and we need to provide\n",
    "                                                            #column names and renames each time\n",
    "df.columns=df.columns.str.lower()\n",
    "df.columns=df.columns.str.replace(' ','_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "457ea1ec-fc22-43bf-a138-644876c664a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#derive new columns discount, sale price and profit\n",
    "df['discount'] = df['list_price']*df['discount_percent']*.01\n",
    "df['sale_price'] = df['list_price'] - df['discount']\n",
    "df['profit']= df['sale_price'] - df['cost_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "250af485-dd60-4ca5-b606-8244de2f1758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert order date from object data type to datetime\n",
    "df.dtypes\n",
    "df['order_date']=pd.to_datetime(df['order_date'], format=\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ca968bc-5add-4cd9-9421-9e201058fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns: cost price, list price and discount percent\n",
    "\n",
    "df.drop(columns=['cost_price','list_price','discount_percent'], inplace=True)\n",
    "\n",
    "# we have used inplace argument so the change would be reflected permanently \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cbc950-6cec-43af-879e-b8fc974c93bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data into sql server using replace option\n",
    "!pip install sqlalchemy pyodbc\n",
    "import sqlalchemy as sal\n",
    "engine = sal.create_engine('mssql://LAPTOP-HDFJR04B\\SQLEXPRESS/master?driver=ODBC+DRIVER+17+FOR+SQL+SERVER')\n",
    "conn=engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef973e-8b14-4507-8efb-46c05046b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into sql server using append command \n",
    "\n",
    "#df.to_sql('df_orders', con=conn, index=False, if_exists= 'replace')\n",
    "                                                                    \n",
    "                                                                    # we have used to_sql() in order to load the df dataframe into SQL and \n",
    "                                                                   #kept the index=false, it means we don't want index id,\n",
    "                                                                    # we want the columns starting from order_id, exclude the index column \n",
    "#when we used if_exists='replace' option in upper query, it created\n",
    "#max value of datatypes in sql(bigint, varchar(max) etc) which takes alot of memory so we dropped the df_orders table in sql and we will create a new table there \n",
    "#and we will append the data there.\n",
    "\n",
    "df.to_sql('df_orders', con=conn, index=False, if_exists= 'append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
